{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제 1유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('USArrests.csv')\n",
    "# print(df)\n",
    "\n",
    "urban60 = df[df['UrbanPop'] >= 60]\n",
    "# print(urban60)\n",
    "\n",
    "result = urban60['Assault'] / (urban60['Murder'] + urban60['Assault'])\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.453\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('swiss.csv')\n",
    "# print(df)\n",
    "\n",
    "sorted_df = df.sort_values('Fertility').reset_index()\n",
    "sorted_df.index = list(range(1, len(sorted_df) + 1))\n",
    "# print(sorted_df)\n",
    "\n",
    "odd_df = sorted_df.iloc[::2]\n",
    "# print(odd_df)\n",
    "even_df = sorted_df.iloc[1::2]\n",
    "# print(even_df)\n",
    "\n",
    "print(round(odd_df['Fertility'].mean() - even_df['Fertility'].mean(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('CO2.csv')\n",
    "# print(df['Type'].value_counts())\n",
    "df['Type'] = df['Type'].apply(lambda x : x.replace('/', ''))\n",
    "# print(df['Type'].value_counts())\n",
    "\n",
    "conc2 = []\n",
    "for i in df['conc']:\n",
    "    i = str(i)\n",
    "    if len(i) >= 3:\n",
    "        if i[-1] == '5' or i[-3] == '5':\n",
    "            conc2.append(True)\n",
    "        else:\n",
    "            conc2.append(False)\n",
    "    else:\n",
    "        if i[-1] == '5':\n",
    "            conc2.append(True)\n",
    "        else:\n",
    "            conc2.append(False)\n",
    "\n",
    "df['conc2'] = conc2\n",
    "# print(df)\n",
    "\n",
    "result = df[(df['Type'] == 'Mississippi') & (df['conc2'] == True)]\n",
    "print(len(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제 2유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3120, 58) (780, 58) (3120,) (780,)\n",
      "0.5799776904049085 2360.5396500950205\n",
      "0.5986873844971197 2347.977639968425\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv('BlackFriday_X_train.csv')\n",
    "X_test = pd.read_csv('BlackFriday_X_test.csv')\n",
    "y_train = pd.read_csv('BlackFriday_y_train.csv')\n",
    "y_test = pd.read_csv('BlackFriday_y_test.csv')\n",
    "\n",
    "# print(X_train.head())\n",
    "# print(y_train.head())\n",
    "\n",
    "y_train = y_train['Purchase']\n",
    "y_test = y_test['Purchase']\n",
    "\n",
    "# print(X_train.info()) # Product_Category_2, Product_Category_3 결측치 존재\n",
    "# print(X_test.info()) # Product_Category_2, Product_Category_3 결측치 존재\n",
    "\n",
    "# User_ID 컬럼 삭제\n",
    "X_train.drop('User_ID', axis=1, inplace=True)\n",
    "X_test.drop('User_ID', axis=1, inplace=True)\n",
    "\n",
    "# print(X_train.info())\n",
    "# print(X_test.info())\n",
    "\n",
    "# Product_ID 컬럼 삭제\n",
    "# print(len(X_train['Product_ID'].unique())) # 범주가 너무 많음 (제거)\n",
    "X_train.drop('Product_ID', axis=1, inplace=True)\n",
    "X_test.drop('Product_ID', axis=1, inplace=True)\n",
    "\n",
    "# print(X_train.info())\n",
    "# print(X_test.info())\n",
    "\n",
    "# Gender (이상 없음)\n",
    "# print(X_train['Gender'].value_counts())\n",
    "# print(X_test['Gender'].value_counts())\n",
    "\n",
    "Gender_OH_train = pd.get_dummies(X_train['Gender'], prefix='Gender')\n",
    "Gender_OH_test = pd.get_dummies(X_test['Gender'], prefix='Gender')\n",
    "\n",
    "# 기존 컬럼 삭제\n",
    "X_train.drop('Gender', axis=1, inplace=True)\n",
    "X_test.drop('Gender', axis=1, inplace=True)\n",
    "\n",
    "# print(X_train['Gender'].value_counts())\n",
    "\n",
    "# Age\n",
    "# print(X_train['Age'].value_counts())\n",
    "# print(X_test['Age'].value_counts())\n",
    "\n",
    "Age_OH_train = pd.get_dummies(X_train['Age'], prefix='Age')\n",
    "Age_OH_test = pd.get_dummies(X_test['Age'], prefix='Age')\n",
    "\n",
    "# print(Age_OH_train)\n",
    "\n",
    "# 기존 컬럼 삭제\n",
    "X_train.drop('Age', axis=1, inplace=True)\n",
    "X_test.drop('Age', axis=1, inplace=True)\n",
    "\n",
    "# Occupation\n",
    "# print(X_train['Occupation'].value_counts())\n",
    "# print(X_test['Occupation'].value_counts())\n",
    "\n",
    "Occupation_OH_train = pd.get_dummies(X_train['Occupation'], prefix='Occupation')\n",
    "Occupation_OH_test = pd.get_dummies(X_test['Occupation'], prefix='Occupation')\n",
    "\n",
    "# 기존 컬럼 삭제\n",
    "X_train.drop('Occupation', axis=1, inplace=True)\n",
    "X_test.drop('Occupation', axis=1, inplace=True)\n",
    "\n",
    "# print(X_train.info())\n",
    "\n",
    "# City_Category\n",
    "# print(X_train['City_Category'].value_counts())\n",
    "\n",
    "City_Category_OH_train = pd.get_dummies(X_train['City_Category'], prefix='City_Category')\n",
    "City_Category_OH_test = pd.get_dummies(X_test['City_Category'], prefix='City_Category')\n",
    "\n",
    "# 기존 컬럼 삭제\n",
    "X_train.drop('City_Category', axis=1, inplace=True)\n",
    "X_test.drop('City_Category', axis=1, inplace=True)\n",
    "\n",
    "# print(X_train.info())\n",
    "\n",
    "# Stay_In_Current_City_Years\n",
    "# print(X_train['Stay_In_Current_City_Years'].value_counts())\n",
    "\n",
    "Stay_In_Current_City_Years_OH_train = pd.get_dummies(X_train['Stay_In_Current_City_Years'],\n",
    "                                                     prefix='Stay_In_Current_City_Years')\n",
    "Stay_In_Current_City_Years_OH_test = pd.get_dummies(X_test['Stay_In_Current_City_Years'],\n",
    "                                                    prefix='Stay_In_Current_City_Years')\n",
    "\n",
    "# 기존 컬럼 삭제\n",
    "X_train.drop('Stay_In_Current_City_Years', axis=1, inplace=True)\n",
    "X_test.drop('Stay_In_Current_City_Years', axis=1, inplace=True)\n",
    "\n",
    "# print(X_train.info())\n",
    "\n",
    "# Marital_Status\n",
    "# print(X_train['Marital_Status'].value_counts())\n",
    "\n",
    "Marital_Status_OH_train = pd.get_dummies(X_train['Marital_Status'], prefix='Marital_Status')\n",
    "Marital_Status_OH_test = pd.get_dummies(X_test['Marital_Status'], prefix='Marital_Status')\n",
    "\n",
    "# Product_Category_1\n",
    "# print(X_train['Product_Category_1'].value_counts())\n",
    "\n",
    "Product_Category_1_OH_train = pd.get_dummies(X_train['Product_Category_1'],\n",
    "                                             prefix='Product_Category_1')\n",
    "Product_Category_1_OH_test = pd.get_dummies(X_test['Product_Category_1'],\n",
    "                                            prefix='Product_Category_1')\n",
    "\n",
    "# 기존 컬럼 삭제\n",
    "X_train.drop('Product_Category_1', axis=1, inplace=True)\n",
    "X_test.drop('Product_Category_1', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "drop_col = ['Product_Category_2', 'Product_Category_3']\n",
    "\n",
    "X_train.drop(drop_col, axis=1, inplace=True)\n",
    "X_test.drop(drop_col, axis=1, inplace=True)\n",
    "\n",
    "# print(X_train.info())\n",
    "# print(X_test.info())\n",
    "\n",
    "X_train = pd.concat([X_train, Age_OH_train, Occupation_OH_train, City_Category_OH_train,\n",
    "                     Stay_In_Current_City_Years_OH_train, Product_Category_1_OH_train,\n",
    "                     Gender_OH_train, Marital_Status_OH_train], axis=1)\n",
    "X_test = pd.concat([X_test, Age_OH_test, Occupation_OH_test, City_Category_OH_test,\n",
    "                     Stay_In_Current_City_Years_OH_test, Product_Category_1_OH_test,\n",
    "                     Gender_OH_test, Marital_Status_OH_test], axis=1)\n",
    "\n",
    "# 기존 컬럼 삭제\n",
    "X_train.drop('Marital_Status', axis=1, inplace=True)\n",
    "X_test.drop('Marital_Status', axis=1, inplace=True)\n",
    "\n",
    "# print(X_train)\n",
    "# print(X_test.info())\n",
    "# print(X_test)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_trainDF, X_validDF, y_trainSR, y_validSR = train_test_split(X_train, y_train, train_size=0.8,\n",
    "                                                              random_state=2024)\n",
    "print(X_trainDF.shape, X_validDF.shape, y_trainSR.shape, y_validSR.shape)\n",
    "#----------------------------------------------------\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# rf = RandomForestRegressor(random_state=2024)\n",
    "# rf.fit(X_trainDF, y_trainSR)\n",
    "\n",
    "# pred_y_valid_rf = rf.predict(X_validDF)\n",
    "\n",
    "# from sklearn.metrics import *\n",
    "# r2_rf = r2_score(y_validSR, pred_y_valid_rf)\n",
    "# mae_rf = mean_absolute_error(y_validSR, pred_y_valid_rf)\n",
    "# print(r2_rf, mae_rf)\n",
    "# #----------------------------------------------------\n",
    "# from xgboost import XGBRegressor\n",
    "# xgb = XGBRegressor(random_state=2024)\n",
    "# xgb.fit(X_trainDF, y_trainSR)\n",
    "\n",
    "# pred_y_valid_xgb = xgb.predict(X_validDF)\n",
    "\n",
    "# from sklearn.metrics import *\n",
    "# r2_xgb = r2_score(y_validSR, pred_y_valid_xgb)\n",
    "# mae_xgb = mean_absolute_error(y_validSR, pred_y_valid_xgb)\n",
    "# print(r2_xgb, mae_xgb)\n",
    "#----------------------------------------------------\n",
    "from lightgbm import LGBMRegressor\n",
    "lgb = LGBMRegressor(random_state=2024)\n",
    "lgb.fit(X_trainDF, y_trainSR)\n",
    "\n",
    "pred_y_valid_lgb = lgb.predict(X_validDF)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "r2_lgb = r2_score(y_validSR, pred_y_valid_lgb)\n",
    "mae_lgb = mean_absolute_error(y_validSR, pred_y_valid_lgb)\n",
    "print(r2_lgb, mae_lgb)\n",
    "\n",
    "pred_y_test_lgb = lgb.predict(X_test)\n",
    "output = pd.DataFrame({\n",
    "    'Purchase' : pred_y_test_lgb\n",
    "})\n",
    "# print(output)\n",
    "output.to_csv('result.csv', index=False)\n",
    "\n",
    "r2_lgb_test = r2_score(y_test, pred_y_test_lgb)\n",
    "mae_lgb_test = mean_absolute_error(y_test, pred_y_test_lgb)\n",
    "print(r2_lgb_test, mae_lgb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제 3유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "10\n",
      "0.0404\n",
      "기각\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import *\n",
    "\n",
    "df = pd.read_csv('survey.csv', encoding='cp949')\n",
    "# print(df)\n",
    "\n",
    "man = df[df['성별'] == '남']['1번문항']\n",
    "woman = df[df['성별'] == '여']['1번문항']\n",
    "\n",
    "# print(man.value_counts())\n",
    "# print(woman.value_counts())\n",
    "\n",
    "# print(df.isna().sum())\n",
    "\n",
    "crosstab = pd.crosstab(df['성별'], df['1번문항'])\n",
    "\n",
    "stat, pvalue, dof, exp_freq = chi2_contingency(crosstab)\n",
    "\n",
    "# print(crosstab)\n",
    "\n",
    "# (a)\n",
    "print(int(exp_freq[0][2]))\n",
    "\n",
    "# (b)\n",
    "print(int(stat))\n",
    "\n",
    "# (c)\n",
    "print(round(pvalue, 4))\n",
    "print('기각')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.63\n",
      "2.32\n",
      "1.1335\n",
      "채택\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import *\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Cars93.csv')\n",
    "# print(df.info())\n",
    "\n",
    "# print(df['Origin'].value_counts()) # USA, non-USA\n",
    "# print(df['Origin'].isna().sum()) # 결측치 없음\n",
    "usa = df[df['Origin'] == 'USA']['Max_Price']\n",
    "non_usa = df[df['Origin'] == 'non-USA']['Max_Price']\n",
    "\n",
    "# (a)\n",
    "print(round(non_usa.mean() - usa.mean(), 2))\n",
    "\n",
    "# (b)\n",
    "stat, pvalue = ttest_ind(non_usa, usa, equal_var=False, alternative='less')\n",
    "# stat = (non_usa.mean() - usa.mean()) / se\n",
    "se = (non_usa.mean() - usa.mean()) / stat\n",
    "print(round(se, 2))\n",
    "\n",
    "# (c)\n",
    "print(round(stat, 4))\n",
    "# print(pvalue)\n",
    "print('채택')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
